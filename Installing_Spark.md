# Установка Apache Spark на ALT Workstation K 10.4 (Sorbaronia Mitschurinii)

## Шаг 1: Скачивание `Spark`

Сначала скачайте последнюю версию Spark с официального сайта `Apache Spark`. Вы можете сделать это, перейдя по [ссылке](https://spark.apache.org/downloads.html) и выбрав последнюю версию Spark.

## Шаг 2: Проверка загруженного файла Spark

Убедитесь, что файл Spark например (`spark-3.5.3-bin-hadoop3.tgz`) был загружен в директорию `/home/executor/Загрузки` или измените на вашу директорию.


## Шаг 3: Распаковка файла

Откройте терминал и перейдите в директорию `Загрузки`:

```bash
cd /home/executor/Загрузки
```

Затем разархивируйте скачанный файл с помощью команды `tar`:

```bash
tar -xvzf spark-3.5.5-bin-hadoop3.tgz
```

## Шаг 4: Установка Spark

После распаковки вы должны переместить разархивированную директорию Spark в `/opt/spark`. Это можно сделать с помощью команды `mv`:

```bash
sudo mv spark-3.5.3-bin-hadoop3 /opt/spark
```

## Шаг 5: Обновление переменных окружения

Теперь Spark установлен в директории `/opt/spark`. Но вам нужно обновить переменные окружения, чтобы система знала, где искать `Spark`. Для этого нужно обновить файл `.bashrc`. Вы можете открыть этот файл в текстовом редакторе с помощью команды `KWrite` (или любого другого редактора, который вам нравится):

```bash
KWrite ~/.bashrc
```

В конец файла нужно следующие строки:

```bash
export SPARK_HOME=/opt/spark
export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin
```

Затем нужно сохранить файл и выйдти из редактора.

## Шаг 6: Применение изменений

Чтобы обновления вступили в силу, нужно применить изменения в файле `.bashrc`. Это можно сделать, выполнив следующую команду:

```bash
source ~/.bashrc
```

## Шаг 7: Проверка установки

Теперь у вас должна быть установлена новая версия Spark. Чтобы проверить это, вы можете ввести следующую команду в терминал:

```bash
spark-submit --version
```
Это должно показать версию Spark, которую вы только что установили.